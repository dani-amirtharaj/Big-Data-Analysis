# To check if the mapper and reducer work on sample
head -n1000 /src/NYT/Data/Pre-Processed\ Articles/classical.txt | /src/NYT/WCount_MR/mapper.py | sort | /src/NYT/WCount_MR/reducer.py

# Creating input directories on HDFS and copying data from local FS to HDFS
hadoop fs -mkdir /user/input/
hadoop fs -mkdir /user/input/nyt/
cd src/NYT/Data/Pre-Processed\ NYT\ Articles/
hadoop fs -put * /user/input/nyt/

# Submitting job to Hadoop with mapper, reducer, input and output directories for small data word count
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming-2.6.0-cdh5.7.0.jar -D mapred.map.tasks=4 -mapper /src/NYT/WCount_MR/mapper.py -reducer /src/NYT/WCount_MR/reducer.py -input /user/input/nyt/music.txt -output /user/output/nyt/swcount/

# Submitting job to Hadoop with mapper, reducer, input and output directories for big data word count
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming-2.6.0-cdh5.7.0.jar -D mapred.map.tasks=4 -mapper /src/NYT/WCount_MR/mapper.py -reducer /src/NYT/WCount_MR/reducer.py -input /user/input/nyt/* -output /user/output/nyt/wcount/

# Submitting job to Hadoop with mapper, reducer, input and output directories for word co-occurence
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming-2.6.0-cdh5.7.0.jar -D mapred.map.tasks=4 -mapper /src/NYT/WCooccurence_MR/mapper.py -reducer /src/NYT/WCooccurence_MR/reducer.py -input /user/input/nyt/* -output /user/output/nyt/wcooccurence/

# Copying output file from HDFS to local FS
hadoop fs -get /user/output/nyt/swcount/ src/NYT/WCount_Output_small/
hadoop fs -get /user/output/nyt/wcount/ src/NYT/WCount_Output_big/
hadoop fs -get /user/output/nyt/wcooccurence/ src/NYT/WCooccurence_Output/